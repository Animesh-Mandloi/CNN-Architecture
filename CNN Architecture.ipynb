{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f8099-1721-4115-8b55-4a70e5d9cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''QUE 1. What is a Convolutional Neural Network (CNN), and why is it used for image processing?\n",
    "A Convolutional Neural Network (CNN) is a specialized type of neural network designed to process structured grid data, such as images.\n",
    "It is particularly effective for tasks like image classification, object detection, and image segmentation because it can automatically\n",
    "learn spatial hierarchies of features. Rather than requiring handcrafted features, CNNs learn features like edges, textures, and \n",
    "complex shapes through their layers,which makes them great for image-related tasks.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d17a2-396e-4bc4-a279-fbbce9dcc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''QUE 2 What are the key components of a CNN architecture?\n",
    "The key components of a CNN architecture are:\n",
    "\n",
    "Convolutional layers: Detect features from the input image.\n",
    "Activation functions (like ReLU): Introduce non-linearity to the model.\n",
    "Pooling layers: Reduce the spatial dimensions of the data.\n",
    "Fully connected layers (FC layers): Perform classification or regression based on the extracted features.\n",
    "Output layer: Produces the final prediction (e.g., class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b0428-8e68-49a5-ac19-86066a67c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 3What is the role of the convolutional layer in CNNs?\n",
    "The convolutional layer applies filters (kernels) to the input image to detect various local patterns such as edges, corners, textures, and\n",
    "other basic features.By convolving (sliding) the filters over the image, the convolutional layer creates feature maps that capture different \n",
    "aspects of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1975e-5df8-45c4-9217-1c51bfda24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 4 What is a filter (kernel) in CNNs?\n",
    "A filter or kernel is a small matrix used in the convolution operation. It slides over the input image and performs element-wise multiplication\n",
    "followed by a sum, extracting specific features like edges, lines, or textures. Each filter learns to detect a different feature in the image,\n",
    "and multiple filters can be used at each convolutional layer to capture a variety of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad9316-ae05-447d-8cd1-1db750dbf842",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 5  What is pooling in CNNs, and why is it important?\n",
    "Pooling is a down-sampling operation that reduces the spatial dimensions of feature maps while retaining important information.\n",
    "It helps reduce the computational load and makes the model more invariant to small translations of the image. Pooling also helps prevent overfitting. \n",
    "There are typically two types of pooling: max pooling and average pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a15f0d-b3ef-46b4-bed3-eb557228a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 6  What are the common types of pooling used in CNNs?\n",
    "Max pooling: Selects the maximum value from a set of values in a specific region of the input feature map.\n",
    "Average pooling: Computes the average value of the values in the region. Max pooling is more commonly used since it retains the most prominent features,\n",
    "making it more robust for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a682d0-9377-40c1-898f-63b969b6d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 7 How does the backpropagation algorithm work in CNNs?\n",
    "In CNNs, backpropagation works by adjusting the weights of the network to minimize the error between the predicted and actual output.\n",
    "The process involves:\n",
    "\n",
    "Forward pass: Input data is passed through the network to make a prediction.\n",
    "Loss calculation: The loss function calculates the error between the predicted output and the true label.\n",
    "Backward pass: The gradients (derivatives) of the loss with respect to the weights are computed using the chain rule.\n",
    "Weight update: Weights are updated using optimization techniques like stochastic gradient descent (SGD) to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2aaa9d-7d9f-449c-9f50-94199ccaab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 8 What is the role of activation functions in CNNs?\n",
    "Activation functions introduce non-linearity into the network. Without them, a CNN would only be able to model linear relationships. \n",
    "Common activation functions include:\n",
    "\n",
    "ReLU (Rectified Linear Unit): Sets negative values to zero and keeps positive values.\n",
    "Sigmoid, Tanh, etc., for different tasks, though ReLU is generally preferred in CNNs because it helps avoid the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9261e6-1346-4ab4-81bc-6cc5b9a2d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 9 What is the concept of receptive fields in CNNs?\n",
    "The receptive field refers to the area of the input image that a particular CNN neuron is sensitive to. In the initial layers, \n",
    "neurons have small receptive fields that capture local features, while in deeper layers, \n",
    "the receptive fields expand to capture more global features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cb4e65-e175-4b47-898b-0e4282b9d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 10 Explain the concept of tensor space in CNNs\n",
    "In CNNs, tensor space refers to the multi-dimensional arrays (tensors) used to represent data as it flows through the network. For example:\n",
    "\n",
    "An image can be represented as a 3D tensor (height x width x channels).\n",
    "Feature maps after convolution are also 3D tensors. This allows CNNs to efficiently handle data with multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb557cf4-41ff-425a-8647-0112bcc73356",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' QUE 11 What is LeNet-5, and how does it contribute to the development of CNNs?\n",
    "LeNet-5 is an early CNN architecture proposed by Yann LeCun for digit recognition, specifically for reading handwritten digits \n",
    "(like those in the MNIST dataset). It was one of the first CNNs and laid the groundwork for modern deep learning,\n",
    "demonstrating the effectiveness of CNNs in image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6db75-2bdd-49f7-88be-5d8462e17dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 12 What is AlexNet, and why was it a breakthrough in deep learning?\n",
    "AlexNet is a deep CNN architecture that won the 2012 ImageNet competition. It was a breakthrough due to its depth (8 layers),\n",
    "use of ReLU activation, and GPU-based parallel processing. \n",
    "AlexNet demonstrated the power of deep learning in computer vision tasks and helped popularize CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49275d1a-105c-496d-bae7-9a0fad64f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 13 What is VGGNet, and how does it differ from AlexNet?\n",
    "VGGNet (specifically VGG16) is a deeper CNN architecture than AlexNet, with 16 layers.\n",
    "It uses smaller 3x3 filters and a consistent architecture (only convolutional layers followed by fully connected layers). \n",
    "It showed that depth, rather than more complex filters, can improve performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5434bde-1b2a-44b0-a575-e565e1802f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 14 What is GoogLeNet, and what is its main innovation?\n",
    "GoogLeNet introduced the Inception module, which allows the network to use multiple filter sizes in parallel (1x1, 3x3, 5x5),and then combines the results.\n",
    "This enables more efficient computation and better feature extraction. GoogLeNet is deeper but has fewer parameters due to this innovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754c652-3f93-41c0-853e-ad2ebff24948",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 15 What is ResNet, and what problem does it solve?\n",
    "ResNet (Residual Networks) solves the problem of vanishing gradients in very deep networks by introducing residual connectionsâ€”skip \n",
    "connections that allow the input of a layer to bypass one or more layers.This helps in training very deep networks without performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70d264-ef8c-421b-9586-9afbf275d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 16 What is DenseNet, and how does it differ from ResNet?\n",
    "DenseNet connects each layer to every other layer in a feed-forward fashion, meaning that each layer receives input from all previous layers. \n",
    "This results in a more efficient use of parameters and helps alleviate the vanishing gradient problem. \n",
    "In contrast, ResNet uses residual connections where only a subset of previous layers are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd2231-44f5-4cc7-ba79-4af5ae189bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' QUE 17 What are the main steps involved in training a CNN from scratch?\n",
    "Training a CNN involves several key steps:\n",
    "\n",
    "Data Preparation: Collect and preprocess the dataset (e.g., image normalization, augmentation).\n",
    "Network Design: Define the architecture (number of layers, types of layers, activation functions).\n",
    "Loss Function Selection: Choose an appropriate loss function for the task (e.g., cross-entropy loss for classification).\n",
    "Forward Pass: Input data is passed through the network to generate predictions.\n",
    "Backpropagation: Compute gradients and adjust weights using optimization methods like SGD.\n",
    "Evaluation: Evaluate performance on a validation set to tune hyperparameters.\n",
    "Iteration: Repeat the process, iterating over the dataset multiple times (epochs) to improve model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194f04c-abf1-4e09-a5e5-2afb6775a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "              # PRACTICAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77282551-3bd8-46a6-89a9-a8d44c459804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 1 Basic Convolution Operation using a filter and a 5x5 image (matrix)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image = np.array([[1, 2, 3, 0, 1],\n",
    "                  [4, 5, 6, 1, 2],\n",
    "                  [7, 8, 9, 3, 4],\n",
    "                  [1, 3, 2, 0, 1],\n",
    "                  [4, 6, 7, 2, 3]])\n",
    "\n",
    "filter = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "output = np.zeros((3, 3))  \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        region = image[i:i+3, j:j+3]\n",
    "        output[i, j] = np.sum(region * filter)\n",
    "\n",
    "print(\"Convolution Output:\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c360a0-7dd9-40f1-8b42-9722ecddeb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 2 Max Pooling on a 4x4 Feature Map with a 2x2 Window\n",
    "\n",
    "feature_map = np.array([[1, 3, 2, 4],\n",
    "                        [5, 6, 7, 8],\n",
    "                        [9, 10, 11, 12],\n",
    "                        [13, 14, 15, 16]])\n",
    "\n",
    "output_pool = np.zeros((2, 2)) \n",
    "for i in range(0, 4, 2):\n",
    "    for j in range(0, 4, 2):\n",
    "        region = feature_map[i:i+2, j:j+2]\n",
    "        output_pool[i//2, j//2] = np.max(region)\n",
    "\n",
    "print(\"Max Pooling Output:\")\n",
    "print(output_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3e8ac-98f3-40c5-95eb-a76b06025515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 3 ReLU Activation Function on a Feature Map\n",
    "\n",
    "def relu(feature_map):\n",
    "    return np.maximum(0, feature_map)\n",
    "\n",
    "output_relu = relu(feature_map)\n",
    "print(\"ReLU Activation Output:\")\n",
    "print(output_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276acb89-bbfe-45ae-8139-7342ba458861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 4 Create a Simple CNN Model with One Convolutional Layer and a Fully Connected Layer using Random Data\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)  \n",
    "y_train = np.random.randint(0, 10, 100)  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a5c56-dfe1-41d7-9aed-ed2d9ef39117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUE 5  Generate a Synthetic Dataset Using Random Noise and Train a Simple CNN Model on It\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)  # Random labels for 10 classes\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85ab43-01cd-43fc-a3ad-a2d50472a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUE 6 Create a Simple CNN Using Keras with One Convolution Layer and a Max-Pooling Layer\n",
    "python\n",
    "Copy\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  # Max-pooling layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fe312-7aad-46ca-9a9e-a590070966d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 7. Add a Fully Connected Layer After the Convolution and Max-Pooling Layers in a CNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03706f89-058f-4353-a4ff-cac20a9b6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 8. Add Batch Normalization to a Simple CNN Model\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(BatchNormalization())  # Batch Normalization after Conv layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b607327-8e0c-47af-8ee8-c508c0f6dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 9. Add Dropout Regularization to a Simple CNN Model\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))  # Dropout layer with 50% rate\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4a97c-a226-4e55-8d11-a9c734d73da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUE 10. Print the Architecture of the VGG16 Model in Keras\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5c7ba-bcc6-4f43-ae84-f48d8971d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Plot the Accuracy and Loss Graphs After Training a CNN Model\n",
    "python\n",
    "Copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a simple CNN model (same as before)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e40fc-16bf-40e6-b65b-ce7ecdb6fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 12. Print the Architecture of the ResNet50 Model in Keras\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "resnet50_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "resnet50_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58188720-d00f-464d-92fb-a68db81c78b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUE 13. Train a Basic CNN Model and Print the Training Loss and Accuracy After Each Epoch\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "X_train = np.random.rand(100, 28, 28, 1)\n",
    "y_train = np.random.randint(0, 10, 100)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
